---
title: 机器学习开放课程
date: 2018-10-22 14:07:13
updated: 2018-10-22
tags:
 - 编程
 - Python
 - 机器学习
categories:
 - 编程
 - Python
 - 机器学习
typora-root-url: 机器学习开放课程
mathjax: true
description: <!—more—->
---

### 三、分类、决策树和K近邻

[机器学习开放课程：三、分类、决策树和K近邻](https://www.jqr.com/article/000139)

#### 决策树

##### 熵

{% blockquote 熵 (信息论) https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA) %}
**熵最好理解为不确定性的量度而不是确定性的量度，因为越随机的信源的熵越大。**

在信息论里面，熵是对不确定性的测量。但是在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。

英语文本数据流的熵比较低，因为英语很容易读懂，也就是说很容易被预测。即便我们不知道下一段英语文字是什么内容，但是我们能很容易地预测，比如，字母e总是比字母z多，或者qu字母组合的可能性总是超过q与任何其它字母的组合。如果未经压缩，一段英文文本的每个字母需要8个比特来编码，但是实际上英文文本的熵大概只有4.7比特。

> 如英语有26个字母，假如每个字母在文章中出现次数平均的话，每个字母的讯息量为：
> $$I_{e}=-\log _{2}{1 \over 26}=4.7$$
{% endblockquote %}

